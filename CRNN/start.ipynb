{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #type: ignore\n",
    "import numpy as np  #type: ignore\n",
    "import matplotlib.pyplot as plt  #type: ignore\n",
    "import matplotlib.image as mpimg  #type: ignore\n",
    "\n",
    "\n",
    "import tensorflow as tf  #type: ignore\n",
    "from keras.models import Model # type: ignore\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout # type: ignore\n",
    "from keras.optimizers import Adam # type: ignore\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"  # The set of valid characters\n",
    "max_str_len = 50                             # Maximum length of input labels\n",
    "num_of_characters = len(alphabets) + 1       # Number of unique characters, plus 1 for CTC pseudo-blank\n",
    "num_of_timestamps = 64   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model_weight = 'trained_model_13_3.h5' # the best model weight\n",
    "#path_to_model_weight = 'trained_model_12_3.h5' # previous version\n",
    "\n",
    "\n",
    "# Define the input layer with a shape of (256, 64, 1) for grayscale images\n",
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "# Convolutional Layer 1: 32 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
    "inner = BatchNormalization()(inner)  # Batch normalization\n",
    "inner = Activation('relu')(inner)  # ReLU activation\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # Max-pooling\n",
    "\n",
    "# Convolutional Layer 2: 64 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# Convolutional Layer 3: 128 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# Reshape the output for sequence processing\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "\n",
    "# Fully Connected Layer 1: 64 units, ReLU activation, He normal initialization\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "# Bidirectional LSTM Layers: 256 units, return sequences\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n",
    "\n",
    "# Output Layer: Number of characters, He normal initialization\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal', name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)  # Softmax activation\n",
    "# Create the model with input and output layers\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "model.load_weights(path_to_model_weight)\n",
    "\n",
    "# The ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # The 2 is critical here since the first couple outputs of the RNN tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# Define input placeholders for true labels, input sequence length, and label sequence length\n",
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "# Calculate CTC loss using the ctc_lambda_func function\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# Create the final model that takes input data, true labels, input length, and label length\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\n",
    "# Compile the final model with a dummy loss lambda function (loss calculation occurs elsewhere)\n",
    "# The optimizer used is Adam with a learning rate of 0.0001\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to preprocess the img\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape                                    # Getting the height & width of the image\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255                    # Blank white image\n",
    "    \n",
    "    # crop    \n",
    "    if h > 64:\n",
    "        img = img[:64, :]                                 # If the h>64 then it is cropped to 64\n",
    "        \n",
    "    if w > 256:\n",
    "        img = img[:, :256]                                # If the w>256 then it is cropped to 256\n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE) # Rotate 90Â° Clockwise & return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    return np.array([alphabets.find(ch) for ch in label])\n",
    "\n",
    "\n",
    "def num_to_label(num):\n",
    "    return ''.join([alphabets[ch] for ch in num if ch != -1])\n",
    "\n",
    "blank_label = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, target_size=(64, 256)):\n",
    "    (h, w) = image.shape\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    scale = min(target_h / h, target_w / w)  # Calculate scale to fit target size\n",
    "    new_h = int(h * scale)\n",
    "    new_w = int(w * scale)\n",
    "    \n",
    "    resized_img = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)  # Resize while preserving aspect ratio\n",
    "    final_img = np.ones((target_h, target_w)) * 255  # Blank white image of target size\n",
    "    final_img[:new_h, :new_w] = resized_img  # Place resized image in top-left corner\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Reshape the image to have a batch size of 1\n",
    "    image = image.reshape(1, 256, 64, 1)\n",
    "    \n",
    "    pred = model.predict(image)\n",
    "    decoded = tf.keras.backend.get_value(\n",
    "        tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0]\n",
    "    )\n",
    "    \n",
    "    return num_to_label(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_prediction(image, window_size=(64, 256), step_size=128):\n",
    "    (h, w) = image.shape\n",
    "    \n",
    "    if h < window_size[0]:  # Pad height if it's smaller than 64\n",
    "        padding_h = window_size[0] - h\n",
    "        image = np.pad(image, ((0, padding_h), (0, 0)), 'constant', constant_values=255)\n",
    "    \n",
    "    if w < window_size[1]:  # Pad width if it's smaller than 256\n",
    "        padding_w = window_size[1] - w\n",
    "        image = np.pad(image, ((0, 0), (0, padding_w)), 'constant', constant_values=255)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for x in range(0, w - window_size[1] + 1, step_size):  # Slide window horizontally\n",
    "        window = image[:, x:x + window_size[1]]  # Extract the window\n",
    "        pred_text = predict(window)  # Predict text in the window\n",
    "        results.append(pred_text)  \n",
    "    \n",
    "    return ''.join(results)  # Combine predictions from all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_fixed_size(image, target_size=(64, 256)):\n",
    "    (h, w) = image.shape\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    if h > target_h:  # Crop height if larger than target\n",
    "        image = image[:target_h, :]\n",
    "    \n",
    "    final_img = np.ones(target_size) * 255  # Blank white image\n",
    "    final_img[:h, :w] = image  # Place original image in top-left corner\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_image(image, part_width=256):\n",
    "    (h, w) = image.shape\n",
    "    results = []\n",
    "    \n",
    "    for start_x in range(0, w, part_width):  # Divide image into sub-images\n",
    "        part_img = image[:, start_x:start_x + part_width]  # Extract part of the image\n",
    "        padded_img = pad_image_to_fixed_size(part_img)  # Pad to fixed size (64, 256)\n",
    "        pred_text = predict(padded_img)  # Predict text for the sub-image\n",
    "        results.append(pred_text)  \n",
    "    \n",
    "    return ''.join(results)  # Combine predictions from all sub-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(image,text):\n",
    "    if(text[-4:]== 'EPTY'):\n",
    "        text = text[:-4]\n",
    "\n",
    "    text = text.replace(' ','')\n",
    "\n",
    "    # image = mpimg.imread(image)\n",
    "    # plt.imshow(image)\n",
    "    # plt.axis('off')  # Menyembunyikan axis\n",
    "    # plt.show()\n",
    "\n",
    "    # print(\"predicted:\",text)\n",
    "    # print(\"len:\",len(text))\n",
    "    # print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_ground_truth(csv_file):\n",
    "    ground_truth_dict = {}\n",
    "    with open(csv_file, mode='r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Lewati header CSV\n",
    "        for row in csv_reader:\n",
    "            image_name = row[0]\n",
    "            ground_truth = row[1].replace(\" \", \"\")  # Menghapus semua spasi\n",
    "            ground_truth_dict[image_name] = ground_truth\n",
    "    return ground_truth_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_char_accuracy(recognized_text, ground_truth):\n",
    "    if(recognized_text[-4:]== 'EPTY'):\n",
    "        recognized_text = recognized_text[:-4]\n",
    "    recognized_text = recognized_text.upper()\n",
    "    ground_truth = ground_truth.upper()\n",
    "\n",
    "    TP = sum(1 for i in range(min(len(recognized_text), len(ground_truth))) if recognized_text[i] == ground_truth[i])\n",
    "    FP = sum(1 for i in range(len(recognized_text)) if i >= len(ground_truth) or recognized_text[i] != ground_truth[i])\n",
    "    FN = sum(1 for i in range(len(ground_truth)) if i >= len(recognized_text) or recognized_text[i] != ground_truth[i])\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    accuracy = TP / max(len(recognized_text), len(ground_truth)) * 100\n",
    "\n",
    "    return accuracy, f1, TP, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix CRNN')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_graph(accuracies, ground_truth_lengths):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ground_truth_lengths, accuracies, marker='o', linestyle='-', color='b', label='Akurasi per Gambar')\n",
    "    plt.xlabel('Panjang String Ground Truth')\n",
    "    plt.ylabel('Akurasi (%)')\n",
    "    plt.title('Akurasi CRNN')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memplot grafik akurasi terhadap nomor iterasi dengan rata-rata\n",
    "def plot_accuracy_vs_iteration(accuracies):\n",
    "    # Menghitung rata-rata kumulatif\n",
    "    avg_accuracies = [sum(accuracies[:i + 1]) / (i + 1) for i in range(len(accuracies))]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(accuracies) + 1), accuracies, marker='o', linestyle='-', color='g', label='Akurasi per Iterasi')\n",
    "    plt.plot(range(1, len(avg_accuracies) + 1), avg_accuracies, marker='', linestyle='--', color='b', label='Rata-rata Kumulatif')\n",
    "    plt.xlabel('Nomor Iterasi')\n",
    "    plt.ylabel('Akurasi (%)')\n",
    "    plt.title('Akurasi CRNN 30 Char dengan Rata-rata Kumulatif') # ganti sesuai keterangan yang sesuai \n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_graph(f1_scores):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(f1_scores) + 1), f1_scores, marker='o', linestyle='-', color='r', label='F1 Score per Gambar')\n",
    "    plt.xlabel('Nomor Gambar')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Convidence CRNN')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_file = '../Capital/26-30/GROUND_TRUTH30.csv'  # Ganti dengan path file CSV Anda\n",
    "ground_truth_dict = read_ground_truth(ground_truth_file)\n",
    "\n",
    "# Variabel untuk menghitung confusion matrix dan F1 score total\n",
    "all_true = []\n",
    "all_pred = []\n",
    "f1_scores = []\n",
    "\n",
    "# Variabel untuk menyimpan akurasi per gambar\n",
    "accuracies = []\n",
    "ground_truth_lengths = []  # Menyimpan panjang karakter ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-4\n",
    "for i in range(1,11):\n",
    "    print(f'index {i}')\n",
    "    print('prepared image to analyse')\n",
    "    name = f'../Capital/26-30/TEST_{i}.png' # Ganti dengan path gambar yang dinginkan\n",
    "    image = cv2.imread(name, cv2.IMREAD_GRAYSCALE)  # Read grayscale image\n",
    "    \n",
    "    image_name = f'TEST_{i}.png'\n",
    "    ground_truth = ground_truth_dict.get(image_name, \"\")\n",
    "    ground_truth = ground_truth.upper()\n",
    "     \n",
    "    \n",
    "    # Menghitung akurasi karakter, F1 score, dan confusion matrix\n",
    "    result_text = process_large_image(image).upper().replace(' ', '')\n",
    "    accuracy, f1, TP, FP, FN = calculate_char_accuracy(result_text, ground_truth)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "\n",
    "    all_true.extend(list(ground_truth.upper()))  # Menyimpan ground truth\n",
    "    if result_text:  # Pastikan recognized_text tidak kosong\n",
    "        all_pred.extend(list(result_text.upper()))  # Menyimpan hasil pengenalan\n",
    "    else:\n",
    "        all_pred.extend([''] * len(ground_truth))  # Menambahkan karakter kosong jika tidak ada teks yang dikenali\n",
    "    \n",
    "    # Menyimpan akurasi per gambar dan panjang karakter ground truth\n",
    "    accuracies.append(accuracy)\n",
    "    ground_truth_lengths.append(len(ground_truth))  # Menyimpan panjang karakter ground truth\n",
    "\n",
    "    print(f\"Gambar {i} - Akurasi: {accuracy:.2f}% - F1 Score: {f1:.2f} - TP: {TP} - FP: {FP} - FN: {FN}\")\n",
    "\n",
    "if len(all_true) > len(all_pred):\n",
    "    all_pred.extend([''] * (len(all_true) - len(all_pred)))  # Padding untuk all_pred\n",
    "elif len(all_true) < len(all_pred):\n",
    "    all_true.extend([''] * (len(all_pred) - len(all_true)))  # Padding untuk all_true\n",
    "\n",
    "# Menghitung confusion matrix secara keseluruhan\n",
    "conf_matrix = confusion_matrix(all_true, all_pred, labels=list(set(all_true + all_pred)))\n",
    "f1_total = f1_score(all_true, all_pred, average='weighted')\n",
    "\n",
    "# Menampilkan confusion matrix dan F1 score total\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Total F1 Score (Weighted): {f1_total:.2f}\")\n",
    "\n",
    "labels = sorted(set(all_pred))\n",
    "\n",
    "# Menampilkan confusion matrix dalam bentuk plot menggunakan fungsi yang Anda definisikan\n",
    "plot_confusion_matrix(all_true, all_pred,labels )\n",
    "\n",
    "# Membuat grafik akurasi berdasarkan panjang karakter ground truth\n",
    "# plot_accuracy_graph(accuracies, ground_truth_lengths)\n",
    "plot_accuracy_vs_iteration(accuracies)\n",
    "\n",
    "plot_f1_graph(f1_scores)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
